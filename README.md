# Word-Based Sentiment Scoring and Trend Analysis on Historical Texts
Project Overview - This project processes historical texts from Project Gutenberg using Hadoop MapReduce and Hive. The goal is to clean the data, compute word frequencies, perform sentiment analysis, analyze trends over time, and extract bigrams using a Hive UDF.
ðŸ“‚ project_root/
â”œâ”€â”€ ðŸ“‚ data/                 # Raw dataset (books in text format)
â”œâ”€â”€ ðŸ“‚ scripts/              # Bash scripts for running jobs
â”œâ”€â”€ ðŸ“‚ src/                  # Java source code for MapReduce jobs
â”‚   â”œâ”€â”€ Preprocessing.java   # Task 1: Data Cleaning
â”‚   â”œâ”€â”€ WordFrequency.java   # Task 2: Word Frequency & Lemmatization
â”‚   â”œâ”€â”€ SentimentAnalysis.java # Task 3: Sentiment Scoring
â”‚   â”œâ”€â”€ TrendAnalysis.java   # Task 4: Trend Aggregation
â”‚   â”œâ”€â”€ BigramUDF.java       # Task 5: Hive UDF for Bigram Analysis
â”œâ”€â”€ ðŸ“‚ hive/                 # Hive-related scripts
â”‚   â”œâ”€â”€ create_table.hql     # Creates Hive tables
â”‚   â”œâ”€â”€ load_data.hql        # Loads data into Hive
â”‚   â”œâ”€â”€ bigram_query.hql     # Runs bigram analysis
â”œâ”€â”€ ðŸ“œ README.md             # Setup and execution guide
â””â”€â”€ ðŸ“œ report.pdf            # Documentation and insights
